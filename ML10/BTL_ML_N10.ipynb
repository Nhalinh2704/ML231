{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6o3n7eaN4U9w",
        "yB_mQ4j19SyY"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Xây dựng model nhận dạng ký tự mã Morse\n",
        "Bài tập lớn: Máy học cơ bản và ứng dụng\n",
        "\n",
        "Nhóm 10_L01_HK231\n",
        "\n",
        "Tô Bạch Long_2011559\n",
        "\n",
        "Tạ Thị Nhã Linh_ 2013642\n"
      ],
      "metadata": {
        "id": "6OdprsGUBNSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Giải nén thư mục và thêm thư viện"
      ],
      "metadata": {
        "id": "_Ta0tTrS4MgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "YAiVpcAyTeRa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "f4b8be3d-0b51-478a-9574-23e29a498f57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4996ee3d8d09>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pymKOLYxLzB"
      },
      "outputs": [],
      "source": [
        "! mkdir '/content/dataset'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "! unzip '/content/gdrive/MyDrive/ML_231/morse-dataset-master.zip' -d '/content/dataset'"
      ],
      "metadata": {
        "id": "aBFaOGpBz1mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import json\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Flatten, Conv2D\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "QvPoTlBM0bVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Phân tập dữ liệu"
      ],
      "metadata": {
        "id": "6o3n7eaN4U9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(filename):\n",
        "    '''\n",
        "    General case to load any data from filename\n",
        "    Output tuple:\n",
        "        xtr, ytr : Data and labels for training\n",
        "        xva, yva : Data and labels for validation\n",
        "        xte, yte : Data and labels for test\n",
        "    '''\n",
        "    loaded = np.load(filename)\n",
        "    xtr = loaded['xtr']\n",
        "    ytr = loaded['ytr']\n",
        "    xva = loaded['xva']\n",
        "    yva = loaded['yva']\n",
        "    xte = loaded['xte']\n",
        "    yte = loaded['yte']\n",
        "    return (xtr, ytr, xva, yva, xte, yte)"
      ],
      "metadata": {
        "id": "Iu-abOih1LVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '/content/dataset/morse-dataset-master/baseline.npz'"
      ],
      "metadata": {
        "id": "v7QjFjYf1Tn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, ytrain, xval, yval, xtest, ytest = load_data(filename = '/content/dataset/morse-dataset-master/baseline.npz')"
      ],
      "metadata": {
        "id": "FgJSFbhs0R8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain[1]"
      ],
      "metadata": {
        "id": "IP28AFKpZsJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kích thước ảnh đầu ra\n",
        "width = 64\n",
        "height = 1\n",
        "# random_image = random.choice(X_val)\n",
        "# print(class_names[Y_val[random_image.]])\n",
        "random_index = np.random.randint(0, len(xtest))\n",
        "random_image = xtest[random_index]\n",
        "true_label = ytest[random_index]\n",
        "# Vector đầu vào\n",
        "vector = random_image  # Giá trị của vector tùy thuộc vào yêu cầu của bạn\n",
        "\n",
        "# Chuyển đổi vector thành mảng numpy\n",
        "array = np.array(vector)\n",
        "\n",
        "# Điều chỉnh kích thước mảng thành kích thước ảnh mong muốn\n",
        "array = np.resize(array, (height, width))\n",
        "\n",
        "# Hiển thị ảnh sử dụng matplotlib\n",
        "plt.imshow(array, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "print(true_label)\n",
        "for i in range(64):\n",
        "  if (true_label[i] == 1):\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "0XKag6ceXXUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trích ký tự và mã Morse tương ứng trong data"
      ],
      "metadata": {
        "id": "o4WyjXInC0V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Codebook = np.load('/content/dataset/morse-dataset-master/Codebook.npy', allow_pickle=True).item()"
      ],
      "metadata": {
        "id": "FIvB9a7weP4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Codebook"
      ],
      "metadata": {
        "id": "53Ky1knTtKx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label\n",
        "label = Codebook.keys()\n",
        "label = list(label)"
      ],
      "metadata": {
        "id": "wQOayp6gkhle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label[4]"
      ],
      "metadata": {
        "id": "ha7tELzmbzYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mã Morse tương ứng\n",
        "data_new = Codebook.values()\n",
        "data_new = list(data_new)"
      ],
      "metadata": {
        "id": "iZvDqVDygPKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new"
      ],
      "metadata": {
        "id": "rmD686c9CwqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Xây dựng mô hình"
      ],
      "metadata": {
        "id": "YtdeGXT0oDsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain, xval = xtrain/255.0, xval/255.0"
      ],
      "metadata": {
        "id": "yATc0HqMjVoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(64,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(64, activation='sigmoid'))  # Điều chỉnh số lượng đầu ra thành 64\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(xtrain, ytrain, epochs=10, validation_data=(xval, yval))"
      ],
      "metadata": {
        "id": "gs61vVzb8wUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Lấy độ chính xác tốt nhất từ history cũ\n",
        "# best_accuracy = max(history.history['val_accuracy'])\n",
        "\n",
        "# # Chạy một lần huấn luyện mới với độ chính xác tốt nhất\n",
        "# new_history = model.fit(xtrain, ytrain, epochs=10, validation_data=(xval, yval))"
      ],
      "metadata": {
        "id": "k-LbgcRbFTXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Lấy độ chính xác tốt nhất từ history cũ\n",
        "# best_accuracy = max(new_history.history['val_accuracy'])\n",
        "\n",
        "# # Chạy một lần huấn luyện mới với độ chính xác tốt nhất\n",
        "# new_history = model.fit(xtrain, ytrain, epochs=10, validation_data=(xval, yval))"
      ],
      "metadata": {
        "id": "khBQrMyHGkOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Lấy độ chính xác tốt nhất từ history cũ\n",
        "# best_accuracy = max(new_history.history['val_accuracy'])\n",
        "\n",
        "# # Chạy một lần huấn luyện mới với độ chính xác tốt nhất\n",
        "# history = model.fit(xtrain, ytrain, epochs=10, validation_data=(xval, yval))"
      ],
      "metadata": {
        "id": "4LCZbI-CIPAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get loss information\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1,11) #1...  31\n",
        "\n",
        "#show history\n",
        "plt.figure(figsize = (10,6))\n",
        "plt.plot (epochs, train_loss, 'bo-', label='Training Loss')\n",
        "plt.plot (epochs, val_loss, 'ro-', label='validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "UACc8jD6j9ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = np.random.randint(0, len(xval))\n",
        "random_image = xval[random_index]\n",
        "true_label = yval[random_index]\n",
        "random_image = random_image.reshape((1, 64))\n",
        "for i in range(64):\n",
        "      if true_label[i] == 1:\n",
        "          nhan = i\n",
        "plt.imshow(random_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title(data_new[nhan])\n",
        "plt.show()\n",
        "\n",
        "print(true_label)\n",
        "# 4 pixel trở lên -\n",
        "#"
      ],
      "metadata": {
        "id": "CV9nwe-IAWM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = np.random.randint(0, len(xval))\n",
        "random_image = xval[random_index]\n",
        "true_label = yval[random_index]\n",
        "random_image = random_image.reshape((1, 64))\n",
        "for i in range(64):\n",
        "      if true_label[i] == 1:\n",
        "          nhan = i\n",
        "# print(random_image.shape)\n",
        "#make predictions\n",
        "predictions = model.predict(random_image)\n",
        "# print(predictions)\n",
        "\n",
        "#get the predicted label\n",
        "predicted_label = np.argmax(predictions)\n",
        "# for i in range(64):\n",
        "#       if predicted_label[i] == 1:\n",
        "#           predict = i\n",
        "# print(data_new[predicted_label])\n",
        "#Plot the image\n",
        "plt.figure(figsize=(8,8))\n",
        "# plt.imshow(random_image[0] * 255.0, cmap='gray')\n",
        "plt.imshow(random_image, cmap='gray')\n",
        "plt.title(f'True Label: {data_new[nhan]}\\nPredicted Label: {data_new[predicted_label]}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e8hpael6KSCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train với data mới"
      ],
      "metadata": {
        "id": "GhuPphIxXuUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "file_path = '/content/gdrive/MyDrive/ML/spectrogram_dataset.pkl'\n",
        "\n",
        "# Đọc dữ liệu từ tệp tin\n",
        "with open(file_path, 'rb') as file:\n",
        "    spectrogram_dataset = pickle.load(file)"
      ],
      "metadata": {
        "id": "IF6Uybc-XxPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/gdrive/MyDrive/ML/tap_y.pkl'\n",
        "\n",
        "# Đọc dữ liệu từ tệp tin\n",
        "with open(file_path, 'rb') as file:\n",
        "    tap_y = pickle.load(file)"
      ],
      "metadata": {
        "id": "237QqnV-YH1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrogram_dataset"
      ],
      "metadata": {
        "id": "GIDgeWE-YM_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_val, y_train, y_val = train_test_split(spectrogram_dataset, tap_y, test_size=0.2, random_state=42) #80% dữ liệu gán cho X_train"
      ],
      "metadata": {
        "id": "Jsu0yS9DYeL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vẽ spectrogram\n",
        "def plot_spectrogram(spectrogram, start=0, end=-1):\n",
        "    plt.figure(figsize=(13, 4))\n",
        "    librosa.display.specshow(spectrogram[:, start:end], sr=22050, x_axis='time', y_axis='mel')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Spectrogram')\n",
        "    plt.show()\n",
        "threshold = -15\n",
        "def silence_detection_num(spectrogram, show=False):\n",
        "    mask_num = np.where(spectrogram < threshold, -80, -10)\n",
        "    word_num = np.where(np.any(mask_num == -10, axis=0), '-', '.')\n",
        "#     words = np.split(spectrogram, word_num, axis=1)\n",
        "\n",
        "    if show:\n",
        "        text = translate(word_num)\n",
        "\n",
        "    return mask_num, text\n",
        "\n",
        "def translate(symbols):\n",
        "    symbols = ''.join(symbols)\n",
        "    # Split the morse code into segments of consecutive dots or dashes\n",
        "    segments = re.findall(r'\\.+|-+', symbols)\n",
        "\n",
        "    # Translate to Morse Code\n",
        "    morse = ''\n",
        "    for segment in segments:\n",
        "        if '.' in segment:\n",
        "            if len(segment) > 30:\n",
        "                morse += '|'\n",
        "            elif len(segment) > 5:\n",
        "                morse += ' '\n",
        "        elif '-' in segment:\n",
        "            if len(segment) < 7:\n",
        "                morse += '.'\n",
        "            elif len(segment) >= 7:\n",
        "                morse += '-'\n",
        "\n",
        "    # Translate to Alphabetical Text\n",
        "    ALPHA_TO_MORSE = { 'A':'.-', 'B':'-...',\n",
        "                    'C':'-.-.', 'D':'-..', 'E':'.',\n",
        "                    'F':'..-.', 'G':'--.', 'H':'....',\n",
        "                    'I':'..', 'J':'.---', 'K':'-.-',\n",
        "                    'L':'.-..', 'M':'--', 'N':'-.',\n",
        "                    'O':'---', 'P':'.--.', 'Q':'--.-',\n",
        "                    'R':'.-.', 'S':'...', 'T':'-',\n",
        "                    'U':'..-', 'V':'...-', 'W':'.--',\n",
        "                    'X':'-..-', 'Y':'-.--', 'Z':'--..',\n",
        "                    '1':'.----', '2':'..---', '3':'...--',\n",
        "                    '4':'....-', '5':'.....', '6':'-....',\n",
        "                    '7':'--...', '8':'---..', '9':'----.',\n",
        "                    '0':'-----', ', ':'--..--', '.':'.-.-.-',\n",
        "                    '?':'..--..', '/':'-..-.', '-':'-....-',\n",
        "                    '(':'-.--.', ')':'-.--.-', '=':'-...-'}\n",
        "\n",
        "    MORSE_TO_ALPHA = {'.-': 'A', '-...': 'B',\n",
        "                      '-.-.': 'C', '-..': 'D', '.': 'E',\n",
        "                      '..-.': 'F', '--.': 'G', '....': 'H',\n",
        "                      '..': 'I', '.---': 'J', '-.-': 'K',\n",
        "                      '.-..': 'L', '--': 'M', '-.': 'N',\n",
        "                      '---': 'O', '.--.': 'P', '--.-': 'Q',\n",
        "                      '.-.': 'R', '...': 'S', '-': 'T',\n",
        "                      '..-': 'U', '...-': 'V', '.--': 'W',\n",
        "                      '-..-': 'X', '-.--': 'Y', '--..': 'Z',\n",
        "                      '.----': '1', '..---': '2', '...--': '3',\n",
        "                      '....-': '4', '.....': '5', '-....': '6',\n",
        "                      '--...': '7', '---..': '8', '----.': '9',\n",
        "                      '-----': '0', '--..--': ', ', '.-.-.-': '.',\n",
        "                      '..--..': '?', '-..-.': '/', '-....-': '-',\n",
        "                      '-.--.': '(', '-.--.-': ')', '-...-': '='}\n",
        "\n",
        "    morse_string = morse.strip('|')\n",
        "    words = morse_string.split('|')\n",
        "    word_sequences = [word.split(' ') for word in words] # Output: [['-...-'], ['-.', '--', '.--']]\n",
        "\n",
        "    text = ''\n",
        "    for word in word_sequences:\n",
        "        for char in word:\n",
        "            try:\n",
        "                text += MORSE_TO_ALPHA[char]\n",
        "            except KeyError:\n",
        "                text += '?'\n",
        "        text += ' '\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "86aYCM60b52W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tap_x = []\n",
        "M = 50\n",
        "for i in range(M):\n",
        "    data, text = silence_detection_num(spectrogram_dataset[0], show=True)\n",
        "    tap_x.append(data)\n",
        "    # print(text)\n",
        "    # plot_spectrogram(X_train, end=500)"
      ],
      "metadata": {
        "id": "syJ12PiRcM_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tap_y_new = tap_y[:50]"
      ],
      "metadata": {
        "id": "cYa3yXd3e8L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(tap_x, tap_y_new, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "E03VVsWffJeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(len(X_train[1])):\n",
        "  for i in range(len(X_train[2])):\n",
        "      if X_train[30][j][i] != -80:\n",
        "          print(\"j = \",j)\n",
        "          # print(\"i = \",i)\n",
        "          # (_, 27 28 29, _)"
      ],
      "metadata": {
        "id": "bmzFWYMHiB2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "ma_tran = np.zeros((50, 1, 20232))\n",
        "for k in range(50):\n",
        "    ma_tran[k, 0, :] = np.copy(X_train[0, 28, :])/80 + 1"
      ],
      "metadata": {
        "id": "24vNvQj1su5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ma_tran_1 = []\n",
        "for i in range(len(ma_tran[0][0])):\n",
        "  if ma_tran[0][0][i] != 0:\n",
        "      num = i\n",
        "      break\n",
        "for k in range(num, len(ma_tran[0][0])):\n",
        "   num_1 = ma_tran[0][0][k]\n",
        "   ma_tran_1.append(num_1)\n",
        "# ma_tran_1"
      ],
      "metadata": {
        "id": "rxAsyMitCvvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def division_symbols (ma_tran):\n",
        "        ma_tran_1 = []\n",
        "        for i in range(len(ma_tran)):\n",
        "          if ma_tran[i] != 0:\n",
        "              num = i\n",
        "              break\n",
        "        for k in range(num, len(ma_tran)):\n",
        "          num_1 = ma_tran[k]\n",
        "          ma_tran_1.append(num_1)\n",
        "        matrix = np.zeros([1,64])\n",
        "        symbols = []\n",
        "        sample = []\n",
        "        count = 0\n",
        "        pf_idx = 0\n",
        "       # pfrom = ma_tran[pf_idx]\n",
        "       # pcurrent = pfrom\n",
        "        for p_idx in range(pf_idx, len(ma_tran_1)):\n",
        "            #  print(p_idx)\n",
        "             #sample = matrix\n",
        "             pto = ma_tran_1[p_idx]\n",
        "             if pto!=0 :   # value != 0\n",
        "                sample.append(pto)\n",
        "             else:         # value = 0\n",
        "                # pass\n",
        "                count += 1\n",
        "                if count < 40:\n",
        "                   sample.append(0)\n",
        "                else:\n",
        "                   m = len(sample)\n",
        "                  #  print(m)\n",
        "                   for i in range(m,64) :\n",
        "                        sample.append(0)\n",
        "                   symbols.append(sample)\n",
        "\n",
        "                  #  symbols.append(matrix)\n",
        "                   sample = []\n",
        "\n",
        "            #  break\n",
        "                pf_idx = p_idx\n",
        "            #  pfrom = ma_tran_1[p_idx]\n",
        "            #  pcurrent = pfrom\n",
        "        return symbols"
      ],
      "metadata": {
        "id": "5eNj4grIzN0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ma_tran[0][0]\n",
        "for value in ma_tran[0][0]:\n",
        "    print(value)"
      ],
      "metadata": {
        "id": "BGR_JpjiQpw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols_temp = division_symbols(ma_tran[0][0])"
      ],
      "metadata": {
        "id": "vZbeuwB46K0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols_temp[14]"
      ],
      "metadata": {
        "id": "tIYGN5MYP-am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols_temp_1 = []\n",
        "# rong = np.zeros([64, 1])\n",
        "for i in range(len(symbols_temp)):\n",
        "    if np.sum(symbols_temp[i]) != 0:\n",
        "        symbols_temp_1.append(symbols_temp[i])"
      ],
      "metadata": {
        "id": "K8nkOnDhJDfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(symbols_temp_1)):\n",
        "        symbols_temp_1[i] = np.transpose(symbols_temp_1[i][:64])"
      ],
      "metadata": {
        "id": "uePUG-zcKWCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i= 1\n",
        "# plt.figure(figsize=(8,8))\n",
        "# plt.imshow(symbols_temp_1[i], cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "7CIHNGCHWGnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(xval):\n",
        "        random_image = xval.reshape((1, 64))\n",
        "        predictions = model.predict(random_image)\n",
        "        predicted_label = np.argmax(predictions)\n",
        "        ki_tu_du_doan = label[predicted_label]\n",
        "        return ki_tu_du_doan"
      ],
      "metadata": {
        "id": "z1GVjNkGNgTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "predict_content = dict()\n",
        "for i in range(len(symbols_temp_1)):\n",
        "      predict_content[i] = predict(symbols_temp_1[i])\n",
        "      plt.figure(figsize=(8,8))\n",
        "      symbols_temp_1[i] = np.reshape(symbols_temp_1[i], (1, 64))\n",
        "      plt.imshow(symbols_temp_1[i], cmap='gray')\n",
        "      plt.axis('off')\n",
        "      plt.show()\n",
        "predict_content = ''.join(predict_content.values())\n",
        "print(\"Văn bản dự đoán: \", predict_content)\n",
        "print(\"Van ban dung: \", y_train[0])"
      ],
      "metadata": {
        "id": "iRTHy68eOrKG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}